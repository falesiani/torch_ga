{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_ga import GeometricAlgebra\n",
    "from torch_ga.layers import GeometricProductDense, TensorToGeometric, GeometricToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib\n",
    "# !pip3 install torch torchvision torchaudio\n",
    "# !conda install -y pytorch torchvision -c pytorch\n",
    "# !conda update -n base -c defaults conda\n",
    "# !conda install pytorch_lightning -c conda-forge\n",
    "# !pip install pytorch-lightning\n",
    "# !conda remove -y pytorch torchvision  \n",
    "# !conda install -y pytorch torchvision torchaudio -c pytorch-nightly  #for python 3.11\n",
    "# !micromamba install -y pytorch torchvision -c pytorch\n",
    "# !micromamba install -y matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(batch_size):\n",
    "    # triangle_points = torch.rand([batch_size, 3, 2], minval=-1, maxval=1)\n",
    "    triangle_points = torch.rand([batch_size, 3, 2])\n",
    "    # triangle_points = torch.FloatTensor(shape=[batch_size, 3, 2])\n",
    "    # print(f\"triangle_points.shpae={triangle_points.shape}\")\n",
    "    triangle_points = triangle_points.uniform_(-1, 1)\n",
    "    x, y = triangle_points[..., 0], triangle_points[..., 1]\n",
    "    # print([batch_size, 3, 2])\n",
    "    # print(f\"triangle_points.shpae={triangle_points.shape}\")\n",
    "    # print(f\"x.shpae={x.shape}\")\n",
    "    # print(f\"y.shpae={y.shape}\")\n",
    "    ax, ay, bx, by, cx, cy = x[..., 0], y[..., 0], x[..., 1], y[..., 1], x[..., 2], y[..., 2]\n",
    "    triangle_areas = 0.5 * torch.abs(ax * (by - cy) + bx * (cy - ay) + cx * (ay - by))\n",
    "    return triangle_points, triangle_areas\n",
    "\n",
    "num_samples = 4\n",
    "sample_points, sample_areas = make_batch(num_samples)\n",
    "\n",
    "fig, axes = plt.subplots(1, num_samples, figsize=(12, 4), sharex=True, sharey=True)\n",
    "for i, ax in enumerate(axes):\n",
    "    points = sample_points[i]\n",
    "    area = sample_areas[i]\n",
    "    # center = tf.reduce_mean(points, axis=0)\n",
    "    center = points.mean(dim=0)\n",
    "    ax.scatter(points[..., 0], points[..., 1])\n",
    "    ax.add_patch(plt.Polygon(points))\n",
    "    ax.annotate(\"Area: %.2f\" % area, center)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga = GeometricAlgebra([1, 1])\n",
    "s_indices = [0]\n",
    "v_indices = [1, 2]\n",
    "mv_indices = torch.arange(ga.num_blades)\n",
    "\n",
    "class Squeeze(nn.Module):\n",
    "    def __init_(self):\n",
    "        super().__init__()\n",
    "    def forward(self,x):\n",
    "        return torch.squeeze(x)\n",
    "    \n",
    "model = nn.Sequential(\n",
    "    TensorToGeometric(ga, blade_indices=v_indices),\n",
    "    GeometricProductDense(\n",
    "        ga, units=128, activation=\"relu\",\n",
    "        blade_indices_kernel=mv_indices,\n",
    "        blade_indices_bias=mv_indices,\n",
    "    ),\n",
    "    # GeometricProductDense(\n",
    "    #     ga, units=16, activation=\"relu\",\n",
    "    #     blade_indices_kernel=mv_indices,\n",
    "    #     blade_indices_bias=mv_indices,\n",
    "    # ),\n",
    "    # GeometricProductDense(\n",
    "    #     ga, units=16, activation=\"relu\",\n",
    "    #     blade_indices_kernel=mv_indices,\n",
    "    #     blade_indices_bias=mv_indices,\n",
    "    # ),\n",
    "    GeometricProductDense(\n",
    "        ga, units=1,\n",
    "        blade_indices_kernel=mv_indices,\n",
    "        blade_indices_bias=s_indices,\n",
    "    ),\n",
    "    GeometricToTensor(ga, blade_indices=s_indices),\n",
    "    # nn.Flatten(),\n",
    "    Squeeze(),\n",
    ")\n",
    "\n",
    "# [B, 3, 2]\n",
    "\n",
    "print(\"Samples:\", sample_points)\n",
    "print(\"Model(Samples):\", model(sample_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytorch_lightning\n",
    "# !pip install --upgrade pytorch_lightning\n",
    "# !pip install --no-cache-dir pytorch_lightning\n",
    "# !pip install rich\n",
    "# !pip uninstall -y rich\n",
    "# !pip uninstall -y pytorch_lightning\n",
    "# !pip install --no-cache-dir pygments\n",
    "# !pip uninstall -y pygments\n",
    "# !pip install pygments==2.14\n",
    "# !pip install pygments\n",
    "# !pip install --upgrade rich\n",
    "\n",
    "# !pip list | grep pygments\n",
    "\n",
    "# !conda install -y -c conda-forge pytorch-lightning \n",
    "\n",
    "    # lightning-utilities-0.7.1  |   py38hecd8cb5_0          31 KB\n",
    "    # pytorch-lightning-1.9.3    |     pyhd8ed1ab_0         433 KB  conda-forge\n",
    "    # torchmetrics-0.11.2        |   py38h01d92e1_0         425 KB\n",
    "    \n",
    "    \n",
    "# !conda install -y -c conda-forge rich\n",
    "\n",
    "# !mamba install -y -c conda-forge pytorch-lightning \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_points, train_areas = make_batch(1024)\n",
    "test_points, test_areas = make_batch(128)\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "# import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class Lighting(pl.LightningModule):\n",
    "    def __init__(self,module):\n",
    "        super().__init__()\n",
    "        self.module = module\n",
    "        self.loss = nn.MSELoss()        \n",
    "    def forward(self, x):\n",
    "        return self.module(x)\n",
    "    # def configure_optimizers(self):\n",
    "    #     # return torch.optim.Adam(self.module.parameters(), lr=0.02)\n",
    "    #     return torch.optim.Adam(self.module.parameters(), lr=1e-1)\n",
    "    def configure_optimizers(self):\n",
    "        # optimizer = torch.optim.Adam(self.module.parameters(), lr=2e-2)\n",
    "        optimizer = torch.optim.SGD(self.module.parameters(), lr=2e-2)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "        # ['train_loss', 'train_loss_step', 'val_loss', 'train_loss_epoch'] \"metric_to_track\"\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"train_loss\"}\n",
    "    \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        x,y = batch\n",
    "        y_hat = self.module(x)\n",
    "        loss = self.loss(y,y_hat)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.module(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        self.log(\"val_loss\", loss)        \n",
    "\n",
    "\n",
    "\n",
    "# def compile(model, optimizer,loss,metrics,learning_rate=1e-3):\n",
    "#     if optimizer in ['Adam']: \n",
    "#         optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#     if loss in ['mse']: \n",
    "#         loss = nn.MSELoss()\n",
    "#     return optimizer,loss\n",
    "\n",
    "# def fit(model, x, y, validation_data, epochs, optimizer):\n",
    "#     for ep in epochs:\n",
    "#         for xi,yi in zip(x,y):\n",
    "#             y_ = model(xi)\n",
    "#             loss_ = loss(yi,y_)\n",
    "            \n",
    "        \n",
    "\n",
    "# optimizer, loss = compile(model, optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "# model.fit(x=train_points, y=train_areas, validation_data=(test_points, test_areas), epochs=100)\n",
    "\n",
    "net = Lighting(model)\n",
    "\n",
    "# tr_dataloader = DataLoader(TensorDataset(train_points, train_areas), batch_size=128, shuffle=True, drop_last=True)\n",
    "# va_dataloader = DataLoader(TensorDataset(test_points, test_areas), batch_size=128, shuffle=True, drop_last=True)\n",
    "\n",
    "# tr_dataloader = DataLoader(TensorDataset(train_points, train_areas), batch_size=32, shuffle=True, drop_last=True)\n",
    "# va_dataloader = DataLoader(TensorDataset(test_points, test_areas), batch_size=32, shuffle=False, drop_last=True)\n",
    "\n",
    "tr_dataloader = DataLoader(TensorDataset(train_points, train_areas), batch_size=16, shuffle=True)\n",
    "va_dataloader = DataLoader(TensorDataset(test_points, test_areas), batch_size=16, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "# from pytorch_lightning.callbacks import RichProgressBar\n",
    "\n",
    "# trainer = Trainer(callbacks=[RichProgressBar()])\n",
    "# trainer = pl.Trainer(max_epochs=100,progress_bar_refresh_rate=20,callbacks=[RichProgressBar()]) \n",
    "# trainer = pl.Trainer(max_epochs=10,progress_bar_refresh_rate=2,callbacks=[RichProgressBar()]) \n",
    "# gpus=1,\n",
    "\n",
    "# trainer = pl.Trainer(max_epochs=10,progress_bar_refresh_rate=2) \n",
    "\n",
    "trainer = pl.Trainer(max_epochs=100)\n",
    "\n",
    "trainer.fit(net, train_dataloaders=tr_dataloader, val_dataloaders = va_dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = 10\n",
    "test_points[:ns],test_areas[:ns], model(test_points[:ns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(model.summary())\n",
    "\n",
    "# https://www.pytorchlightning.ai/blog/using-optuna-to-optimize-pytorch-lightning-hyperparameters\n",
    "\n",
    "# def objective(trial):\n",
    "#     # PyTorch Lightning will try to restore model parameters from previous trials if checkpoint\n",
    "#     # filenames match. Therefore, the filenames for each trial must be made unique.\n",
    "#     checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "#         os.path.join(MODEL_DIR, \"trial_{}\".format(trial.number)), monitor=\"accuracy\"\n",
    "#     )\n",
    "\n",
    "#     # The default logger in PyTorch Lightning writes to event files to be consumed by\n",
    "#     # TensorBoard. We create a simple logger instead that holds the log in memory so that the\n",
    "#     # final accuracy can be obtained after optimization. When using the default logger, the\n",
    "#     # final accuracy could be stored in an attribute of the `Trainer` instead.\n",
    "#     logger = DictLogger(trial.number)\n",
    "\n",
    "#     trainer = pl.Trainer(\n",
    "#         logger=logger,\n",
    "#         val_percent_check=PERCENT_TEST_EXAMPLES,\n",
    "#         checkpoint_callback=checkpoint_callback,\n",
    "#         max_epochs=EPOCHS,\n",
    "#         gpus=0 if torch.cuda.is_available() else None,\n",
    "#         early_stop_callback=PyTorchLightningPruningCallback(trial, monitor=\"accuracy\"),\n",
    "#     )\n",
    "\n",
    "#     model = LightningNet(trial)\n",
    "#     trainer.fit(model)\n",
    "\n",
    "#     return logger.metrics[-1][\"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sample_areas = model(sample_points)\n",
    "\n",
    "fig, axes = plt.subplots(1, num_samples, figsize=(20, 5), sharex=True, sharey=True)\n",
    "for i, ax in enumerate(axes):\n",
    "    points = sample_points[i]\n",
    "    area = sample_areas[i]\n",
    "    predicted_area = predicted_sample_areas[i]\n",
    "    center = points.mean(dim=0)\n",
    "    ax.scatter(points[..., 0], points[..., 1])\n",
    "    ax.add_patch(plt.Polygon(points))\n",
    "    ax.annotate(\"Area: %.2f\" % area, center)\n",
    "    ax.annotate(\"Predicted : %.2f\" % predicted_area, center + torch.tensor([0, -0.1]))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sample_areas = model(sample_points)\n",
    "\n",
    "fig, axes = plt.subplots(1, num_samples, figsize=(20, 5), sharex=True, sharey=True)\n",
    "for i, ax in enumerate(axes):\n",
    "    points = sample_points[i]\n",
    "    area = sample_areas[i]\n",
    "    predicted_area = predicted_sample_areas[i]\n",
    "    center = torch.mean(points, dim=0)\n",
    "    ax.scatter(points[..., 0], points[..., 1])\n",
    "    ax.add_patch(plt.Polygon(points))\n",
    "    ax.annotate(\"Area: %.2f\" % area, center)\n",
    "    ax.annotate(\"Predicted area: %.2f\" % predicted_area, center + torch.tensor([0, -0.1]))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_normal = nn.Sequential(\n",
    "    nn.Linear(6,64*2),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64*2,64*2),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64*2,1)\n",
    ")\n",
    "\n",
    "\n",
    "net = Lighting(model_normal)\n",
    "\n",
    "tr_dataloader = DataLoader(TensorDataset(train_points.view(-1,6), train_areas), batch_size=128, shuffle=True, drop_last=True)\n",
    "va_dataloader = DataLoader(TensorDataset(test_points.view(-1,6), test_areas), batch_size=128, shuffle=True, drop_last=True)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=100)\n",
    "\n",
    "trainer.fit(net, train_dataloaders=tr_dataloader, val_dataloaders = va_dataloader)\n",
    "\n",
    "\n",
    "# model_normal.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "# model_normal.fit(x=tf.reshape(train_points, [-1, 6]), y=train_areas, validation_data=(tf.reshape(test_points, [-1, 6]), test_areas), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sample_areas = model_normal(sample_points.view(-1,6))\n",
    "\n",
    "fig, axes = plt.subplots(1, num_samples, figsize=(20, 5), sharex=True, sharey=True)\n",
    "for i, ax in enumerate(axes):\n",
    "    points = sample_points[i]\n",
    "    area = sample_areas[i]\n",
    "    predicted_area = predicted_sample_areas[i]\n",
    "    center = points.mean(dim=0)\n",
    "    ax.scatter(points[..., 0], points[..., 1])\n",
    "    ax.add_patch(plt.Polygon(points))\n",
    "    ax.annotate(\"Area: %.2f\" % area, center)\n",
    "    ax.annotate(\"Predicted : %.2f\" % predicted_area, center + torch.tensor([0, -0.1]))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_normal.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sample_areas = model_normal(torch.reshape(sample_points, [-1, 6]))\n",
    "\n",
    "fig, axes = plt.subplots(1, num_samples, figsize=(20, 5), sharex=True, sharey=True)\n",
    "for i, ax in enumerate(axes):\n",
    "    points = sample_points[i]\n",
    "    area = sample_areas[i]\n",
    "    predicted_area = predicted_sample_areas[i]\n",
    "    center = torch.mean(points, axis=0)\n",
    "    ax.scatter(points[..., 0], points[..., 1])\n",
    "    ax.add_patch(plt.Polygon(points))\n",
    "    ax.annotate(\"Area: %.2f\" % area, center)\n",
    "    ax.annotate(\"Predicted area: %.2f\" % predicted_area, center + torch.tensor([0, -0.1]))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "10ff9cff1e0293119a5a1fdb939fd95de09217e1f26359b091d157f526f5e737"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
